{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Transformation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Transformation "
      ],
      "metadata": {
        "id": "9rosaME0l691"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch is a deep learning framwork used extensively for various tasks like Image Classification , segmentation , object identification. In such cases , we'll have to deal with various types of data and it's probable that most of the time , the data may not be in the desired format we need. That's where transformation come to rescue.\n",
        "\n",
        "The torchvision.transforms module provides image transformations we can use. We use transforms to perform some manipulation of the data and make it suitable for training torchvision module of PyTorch provides transforms for common Image transformations. These transformations can be chained together using compose. "
      ],
      "metadata": {
        "id": "9xGB-D68mBQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) ToTensor"
      ],
      "metadata": {
        "id": "XnM8NaiOsR4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a very commonly used conversion transform. In PyTorch we mostly work with data in the form of tensors , if the input data is in the form of a Numpy array or PIL Image (Python Image Library , which provides the python interpreter with image editing) So we can convert it to a tensor format using ToTensor. The final tensor will be the form (C* H* W). "
      ],
      "metadata": {
        "id": "p0t25jVQsdcL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C-tD91VjluZb",
        "outputId": "487f21a0-543f-4529-9037-07b0d4fec654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1056, 1584])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import urllib.request\n",
        "\n",
        "# Read the input image , if the input image is PIL image , convert it to a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "# convert it to a tensor\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()] )\n",
        "# Applied the above defined transform on the input image to convert it to a tensor\n",
        "img_tensor = transform(img)\n",
        "print(img_tensor.shape) #  The final tensor will be in the form of C*H*w"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zMi-j6t11I5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Normalize "
      ],
      "metadata": {
        "id": "eKxaRG0L-frb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This operation will take a tensor image and normalize it with mean and standard deviation. We need to provide a sequence of means for the 3 channels as parameter \"mean\" and similarity for \"std\". The Normalize() transform normalizes an image with mean and standard deviation , the torchvision transforms module provides many important transforms that can be used to perform different types of manipulations on the image data. Normalize() accepts only tensor images of anysize. A tensor image is a torch tensor. A tensor image may have n number of channels , the normalize() transform normalizes the tensor image for each channel. At this transform supports only tensor image , the PIL image should be first converted to a torch tensor and after applying Normalize() transform , we convert the normalized torch to a PIL image. "
      ],
      "metadata": {
        "id": "wX-b25Ny-kbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "\n",
        "# Read the input image , if the input image is PIL image , convert it to a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# define a transform to normalize the image with mean and standard deviation. Here , we use mean and std to the ImageNet dataset\n",
        "transform_tensor  = transforms.Compose(\n",
        "    [transforms.ToTensor()] \n",
        "    \n",
        "  )\n",
        "image_tensor = transform_tensor(img)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Normalize(mean = (0.485 , 0.456 , 0.406) , std = (0.229 , 0.224 , 0.225))] )\n",
        "\n",
        "# Apply the above defined transform on the input image to normalize the image\n",
        "normalized_image_tensor =  transform(image_tensor)\n",
        "# convert the normalized tensor image to PIL image\n",
        "normalized_img = transforms.ToPILImage()(normalized_image_tensor)\n",
        "# visualize the normalized image\n",
        "normalized_img.show()"
      ],
      "metadata": {
        "id": "nBhyKEwhx6Ip"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Center Crop"
      ],
      "metadata": {
        "id": "8nZOVwTCEpEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To crop an image at it's center , we apply centercrop() , it's one of the transforms provided by the torchvision.transforms module. This module contains many important transformations that can be used to perform manipulation on the image data. CenterCrop :- transformation accepts both PIL and tensor images. A tensor image is a pytorch tensor with shape [c , h , w] , where c is the number of channels , H is the image height and w s the image width. This transform also accepts a batch of tensor images. A batch of tensor images is a tensor with [B , C , H , W] , where B is the number of images in the Batch , if the images is neither a PIL image or a tensor image then we first convert it to a tensor image and then apply the CenterCrop() transformation. \n",
        "\n",
        "Syntax :- `torchvision.transforms.CenterCrop(size)`\n",
        "\n",
        "Parameters :- \n",
        "  Size :- Desired crop size , size is a sequence like (h , w) , where h and w are the height and width of the cropped image. If size is an int , the cropped image will be a square image. It returns the cropped image of a given size. "
      ],
      "metadata": {
        "id": "X1LlSbSmE7CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rectangular crop image"
      ],
      "metadata": {
        "id": "jluun2QQJyHH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "from PIL import Image\n",
        "\n",
        "# Read the input image - The input image is a PIL image or a torch tensor of shape [... , H , W]\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# define a transform to crop the image at its center , the crop size is (200 , 250) for rectangular crop\n",
        "transform = transforms.Compose(\n",
        "    [transforms.CenterCrop(size = (200 , 250))]\n",
        ")\n",
        "# Apply the above defined transform image to crop the image at the center\n",
        "center_croppped_image  = transform(img)\n",
        "# visualize the cropped image\n",
        "center_croppped_image.show()"
      ],
      "metadata": {
        "id": "EjxtEmPgB6hx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Square crop image"
      ],
      "metadata": {
        "id": "srjCZGAYK8_a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch\n",
        "import torchvision.transforms as transforms \n",
        "from PIL import Image\n",
        "\n",
        "# read the input image :- The input image is a PIL image or a torch of shape [.. , H , W]\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# define a transform to crop the image at its center , the crop size is (250 ) for square crop\n",
        "transform = transforms.Compose(\n",
        "    [transforms.CenterCrop(size = (250))]\n",
        ")\n",
        "# Apply the above defined transform image to crop the image at the center\n",
        "center_cropped_image = transform(img)\n",
        "# visualize the croppped image\n",
        "center_cropped_image.show()"
      ],
      "metadata": {
        "id": "QV3ydcW8LRvm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Random Horizontal Flip "
      ],
      "metadata": {
        "id": "0W9OpaE3O8tj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This transformation will flip the image horizontally (random) with a given probability. we can set this probability through the parameter p. The default value of p is 0.5. TO flip an image horizontally in a random fashion with a given probability we apply RandomHorizontalFlip() transform. It's one of the transforms provided by the torchvision.transforms module. This module contains many important transformations that can be used to perform different types of manipulations on the image data. RandomHorizontalFlip() accepts both PIL and tensorimages. A tensor image is a pytorch tensor with shape [C,H,W] where C is the number of channels , H is the image height and w is the image width. \n",
        "\n",
        "Syntax:- `torchvision.transforms.RandomHorizontalFlip(p)(image)`\n",
        "\n",
        "\n",
        "\n",
        "* If p = 1 , it returns a horizontally flipped image  \n",
        "* If p = 0 , it returns the original image\n",
        "\n",
        "\n",
        "* If p is in the range(0,1), then the probability to return the horizontally flipped image is p. It returns a horizontally flipped image randomly with a given probability p. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GWsFn2EbPRvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "from PIL import Image\n",
        "# Read the input image\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "# Define a transform to horizontally flip an image\n",
        "transform = transforms.Compose(\n",
        "     [transforms.RandomHorizontalFlip(p = 1)]                 \n",
        ")\n",
        "\n",
        "# Apply the above defined transform on the input image\n",
        "random_horizontal_flip = transform(img)\n",
        "# Display the image\n",
        "random_horizontal_flip.show()"
      ],
      "metadata": {
        "id": "FQ_gIboHOs4g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Vertical Flip**"
      ],
      "metadata": {
        "id": "lrF-8paiX9Zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply RandomVerticalFlip() transform to flip an image vertically at a random angle with a given probability. It's one of the transforms provided by the torchvision.transforms module. This module contains many important transformations that can be used to perform different types of manipulations on the image data. RandomVerticalFlip() accepts both PIL and tensorimages. A tensor image is a torch tensor with shape [C , H , W] , where C is the number of channels , H is the image height and W is the image width. \n",
        "\n",
        "Syntax:- `torchvision.transforms.RandomVerticalFlip(p)(img)`\n",
        "\n",
        "\n",
        "\n",
        "* If p = 1 , it returns the vertically flipped image\n",
        "* If p = 0 , it returns the vertically the original image\n",
        "* If p is in the range (0,1) , the probability to return the vertically flipped images is p\n",
        "\n",
        "- It returns a vertically flipped image at a random angle with a given probability p\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FdRld7dSYCRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# Read the input image , the input image is a PIL image or a tensor image\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "# Define a transform to vertically flip the image randomly with a given probability p. Here p = 0.25 means \n",
        "# , the chance of any input image to be vertically flipped is 25%\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomVerticalFlip(p = 0.25)]\n",
        ")\n",
        "# Apply the above defined transform on the input image to vertically flip the image\n",
        "random_vertical_flip = transform(img)\n",
        "# Show the output image\n",
        "random_vertical_flip.show()"
      ],
      "metadata": {
        "id": "djn-RmuZWsR6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Rotation"
      ],
      "metadata": {
        "id": "OekHsCNh9i91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rotates an image by a random angle , the chosen random angle is from a given range of angles in degree RandomRotation() is one of the many important transforms provided by the torchvision.transforms module. RandomRotation() transforms accepts both PIL and tensor images , A tensor image is a torch tensor witb shape [C , H , W] , where C is the number of channels , H is the image height and W is the image width , if the image is neither a PIL image nor a tensor image , then we first convert it to a tensor image and then apply transform. \n",
        "\n",
        "Syntax:- `torchvision.transforms.RandomRotation(degree)(img)`"
      ],
      "metadata": {
        "id": "kIP8QIhf9vsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# read the input image , the input image is a PIL image or a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# Define a transform to rotate an image with a random angle , give the desired range of angles\n",
        "transforms = transforms.Compose(\n",
        "    [transforms.RandomRotation((30 , 70))]\n",
        ")\n",
        "# Apply the above defined transform on the input image to rotate the input image with a random angle\n",
        "random_rotation = transforms(img)\n",
        "# Visualize it\n",
        "random_rotation.show()"
      ],
      "metadata": {
        "id": "uJq5o9RAeBcZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gray Scale"
      ],
      "metadata": {
        "id": "k6RRnOoAAxQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This information will change the original RGB image in to grayscale (i.e Black and White) we can provide how many channels we want as input to the parameter \"num_output_channels\". To convert an image to grayscale , we apply Grayscale() transformation. It's one of the transforms provided by the torchvision.transforms module. This module contains many important transformations that can be used to perform different types of manipulations on the image data. GrayScale() transformation accepts both PIL and tensorimages or batch of tensorimags. A tensor image is a PyTorch tensor with shape [3 , H , W] , where H is the image height and w is the image width. A batch of tensor images is also a torch tensor with [B , C , H , W] where B is the number of images in the Batch. \n",
        "\n",
        "Synatax :- `torchvision.transforms.Grayscale(num_output_channels)`\n",
        "It returns a gray scale image\n"
      ],
      "metadata": {
        "id": "UcVXDzfzCV4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Read the input image , the input image is a PIL image or a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# Knowing the number of channels of the image before applying grayscale\n",
        "print(\"The mode of the image before applying grayscale transformation is = {}\".format(img.mode))\n",
        "\n",
        "# Define a transform to convert the original input image to gray scale\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Grayscale(num_output_channels=1)]\n",
        ")\n",
        "# Apply the above defined transform on the input image to convert it to the grayscale\n",
        "grayscale_image = transform(img)\n",
        "# display the image \n",
        "grayscale_image.show()\n",
        "print(\"The mode of the image after applying the grayscale transformation is = {}\".format(grayscale_image.mode))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0W1RHoAAo6D",
        "outputId": "93ceac7c-b58f-4123-dff4-dd960ae54a72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mode of the image before applying grayscale transformation is = RGB\n",
            "The mode of the image after applying the grayscale transformation is = L\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gaussian Blur**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BEx9qkKOIOix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's a process of Blurring an image using a Gaussian Function. The torchvision transforms module provides many important transformations that can be used to perform different types of manipulations on the image data GaussianBlur() transformation is used to blur an image with randomly chosen Gaussian Blur. The Gaussian Blur transformation accepts both PIL and tensor images or a batch of tensor images. A tensor image is a PyTorch tensor with shape [3 , H , W] , where H is the image height and w is the image width. A batch of tensor images is also a torch tensor with [B , 3 , H , w] where B is the number of images in the batch. \n",
        "\n",
        "Syntax:-` torchvision.transforms.GaussianBlur(kernel_size , sigma = (0.1 , 0.2)(img))`\n",
        "\n",
        "Kernel_size :- size of the Gaussian Kernel , it must be a list or tuple of two integers\n",
        "\n",
        "Sigma:- Standard deviation used in creating the Gaussian kernel\n",
        "\n",
        "img:- PIL image or a tensor image to be blurred\n",
        "\n",
        "- It returns a Gaussian blurred image"
      ],
      "metadata": {
        "id": "cyOdY6rrISWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Read the input image , the input image is a PIL image or a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# Define a transform to blur the input image with randomly chosen Gaussian Blur\n",
        "transform = transforms.Compose(\n",
        "    [transforms.GaussianBlur(kernel_size = (7 , 13), sigma = (0.1 , 0.2))]\n",
        ")\n",
        "# Apply the above defined transform on the input image to blur the input image\n",
        "blurred_image = transform(img)\n",
        "# show the blurred image\n",
        "blurred_image.show()"
      ],
      "metadata": {
        "id": "ScFXAAkgGkkg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Apply"
      ],
      "metadata": {
        "id": "7GRAef49LbKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This transformation will randomly apply a given list of transformations with probability "
      ],
      "metadata": {
        "id": "NWXCq5R9MZt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# Read the input image , the input image is a PIL image or a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# All Random Apply to this image\n",
        "transform = transforms.RandomApply(\n",
        "    [transforms.RandomHorizontalFlip() , transforms.RandomRotation(degrees = (30 , 70))] , p = 1\n",
        ")\n",
        "# Apply the transform to the image \n",
        "random_applied_image = transform(img)\n",
        "# visualize the image \n",
        "random_applied_image.show()"
      ],
      "metadata": {
        "id": "wHPKOvWVLZVk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compose "
      ],
      "metadata": {
        "id": "u8YZPwq6O6ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have been using compose() throughout this article , to define it clearly , it composes several transforms together. "
      ],
      "metadata": {
        "id": "7pbox1ArO9bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import RandomRotation\n",
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# Read the input image , the input image is a PIL image or a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "# Define composition of transforms in to this image\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Grayscale(num_output_channels=1) , \n",
        "     transforms.RandomHorizontalFlip(p = 1),\n",
        "     transforms.RandomRotation(degrees = (30,70))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply this transforms to the image\n",
        "composition_of_transforms = transform(img)\n",
        "# visualize the image\n",
        "composition_of_transforms.show()"
      ],
      "metadata": {
        "id": "gFjZ3zbPOQj3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Functional Transforms **"
      ],
      "metadata": {
        "id": "OhVzeinhSMK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In all transformation we learned till now, we can notice that the parameters are generated randomly. This usually is sufficient for data augumentation but sometimes we may require a more fined grained control of the transformation pipeline. In this case , functional transforms can be used , Here we get to specify or generate all the parameters. An added advantage is that a particular defined functional transform can be applied to multiple images.\n",
        "\n",
        "All these functional transforms can be accessed `from torchvision.transforms.\n",
        "functional`\n",
        "\n",
        "Different Functional transformations PyTorch provides\n",
        "\n",
        "*   a) Adjust Brightness\n",
        "*   b) Adjust Contrast\n",
        "*   c) Adjust saturation\n",
        "*   d) Adjust sharpness"
      ],
      "metadata": {
        "id": "IM63wi3uUahh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjust Brightness"
      ],
      "metadata": {
        "id": "i2699NaiWA1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The brightness of an image is a measure of its intensity after the image has been captured. To adjust brightness of an image , we apply adjust brightness() module , this module contains many important functional transformations that can be used to manipulate the image data. `adjust_brightness` transformation accepts both PIL and tensor images. A tensor image is a pytorch tensor with shape [C , H , W]  , where C is number of channels ,H is image height. A batch of tensor images is a tensor with [B , C , H , W] , where B is the number of images in the batch , If the image is neither a PIL image nor a tensor image , then we first convert it to a tensor image and then apply the `adjust_brightness()`\n",
        "\n",
        "Syntax:-` torchvision.transforms.functional.adjust_brightness(img , brightness_factor)`\n",
        "\n",
        "Parameters :- \n",
        "\n",
        "\n",
        "*  Img :- Image of which the brightenss is to be adjusted. It is a PIL image or a torch tensor. It may be a single image or a batch of images\n",
        "*  Brightness_factor :- A non negative float number , 0 gives a black image , 1 gives the original image. If the value is 1 , we'll get the same image as we gave as input , if the value is more than 1 , we'll get a brighter image , if it's less than 1 , we'll get a darker image , we can pass a float image accordingly. \n",
        "\n",
        "- It returns the brightness adjusted image. \n",
        "\n"
      ],
      "metadata": {
        "id": "xyOSQ7QIkRyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Read the input image , the input image can be a PIL image or a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# Adjust the brightness of the image with the desired brightness factor\n",
        "transform_black = transforms.functional.adjust_brightness(img , brightness_factor = 0)\n",
        "\n",
        "transform_original = transforms.functional.adjust_brightness(img , brightness_factor=1)\n",
        "\n",
        "transform_brighter = transforms.functional.adjust_brightness(img , brightness_factor= 4 )\n",
        "\n",
        "transform_float = transforms.functional.adjust_brightness(img , brightness_factor = 0.7)\n"
      ],
      "metadata": {
        "id": "bP0NDQPaj9D6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transform_black.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfiQms7HrrH7",
        "outputId": "be312c41-e7c1-43f4-f5bf-d8103ec9ba14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(transform_original.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y5c1EXNruf0",
        "outputId": "44420607-f915-41b0-8683-d35d3e058e44"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(transform_brighter.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nxbycm9rz_k",
        "outputId": "f5aef060-1fc1-4165-9860-347c08da15c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(transform_float.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q4EyC77r2lU",
        "outputId": "71a5997d-d231-40bc-e888-b4a334084107"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjust The Contrast"
      ],
      "metadata": {
        "id": "4UORbmgHWFVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The contrast of an image refers to the amount of color differentiation that exists between the various features of an image. To adjust the contrast of an image , we apply adjust_contrast(). It's one of the functional transforms provided by the torchvision.transforms module. This module contains many important functional transformations that can be used to perform different types of manipulations on the image data. Adjust_Contrast() transformation accepts both PIL and tensor images. A tensor image is a PyTorch tensor with shape [C , H , W] , where C is the number of channels , H is the image height and w is the image width. This transform also accepts a batch of tensor images which is a tensor with [C , C , H , W] , where B is the number of images in the batch. \n",
        "\n",
        "If the image is neither a PIL image nor a tensor image , then we first convert it to a tensor image and then apply the adjust_contrast(). All the functional transforms can be accessed from torchvision.transforms.functional\n",
        "\n",
        "Parameters:- \n",
        "  \n",
        "* Img:- It is the image of which the contrast is to be adjusted , it's a PIL \n",
        "image or torch tensor. It may be a single image or a batch of images\n",
        "\n",
        "* Contrast_factor :- The second parameter will input a float value that will tell how the contrast has to be adjusted but it can not be negative\n"
      ],
      "metadata": {
        "id": "LQ02cgZnsPpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "from PIL import Image\n",
        "\n",
        "# Read the input image , the input image is a PIL image or a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# Adjust the saturation of the image with the desired saturation factor\n",
        "img_contrast = transforms.functional.adjust_contrast(img , contrast_factor =  1)\n",
        "# visualize the saturation adjusted image\n",
        "img_contrast.show()"
      ],
      "metadata": {
        "id": "a46B8KIusPOW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjust Saturation"
      ],
      "metadata": {
        "id": "f6Lm46_nWKIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The saturation of an image refers to the intensity of a color. The higher the saturation of a color , the more vivid it is , the lower the saturation of a color , the closer it is to grey. To adjust of an image , we apply adjust_saturation() , it's one of the functional transforms provided by the torchvision.transforms module. adjust_saturation() transformation accepts both PIL and tensor images. A tensor image is a PyTorch tensor with shape [C , H  , W] where C is the number of channels , H is the image height and w is the image width. This transform also accepts a batch of tensor images , if the image is neither a PIL image nor a tensor image and then apply adjust saturation() , the saturation value should be a non negative number. \n",
        "\n",
        "Parameters:- \n",
        " ` Img:- ` Image of which saturation is to be adjusted , it is a PIL image or torch tensor. It may be a single image or a batch of images. \n",
        " `Saturation_factor `:- a non - negative number , 0 will give a black and white image , while 1 will give the original image. "
      ],
      "metadata": {
        "id": "1CyUxkZj3IJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Read the input image , the input image is a PIL image or a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# adjust the saturation of the image with a desired saturation factor\n",
        "saturation_transformation = transforms.functional.adjust_saturation(img , saturation_factor = 0)\n",
        "# visualize the saturation adjusted image\n",
        "saturation_transformation.show()"
      ],
      "metadata": {
        "id": "FFdBD7sFzGPP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjust Sharpness"
      ],
      "metadata": {
        "id": "YkXTVIe1WOR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To adjust the sharpness of an image , we apply adjust sharpness(). It's one of the functional transforms provided by the torchvision.transforms provided by the torchvision.transforms module , adjust_sharpness() transformations accepts both PIL and tensor images. A tensor image is a PyTorch tensor with shape [C , H , W] , where C is number of channels , H is the image height and w is the image width. This transform also accepts a batch of tensor images. If the image is neither a PIL image nor a tensor image , then we first convert it to a tensor image and then apply the adjust sharpness()  , the sharpness should be any non-negative number. \n",
        "\n",
        "Parameters:- `img`:- Image of which sharpness is to be adjusted , it is a PIL image or torch tensor , it may be a single image or a batch of images. \n",
        "`sharpness factor` :- A non-negative number  , 0 will be blurred image while 1 will give the original image. "
      ],
      "metadata": {
        "id": "SsGjPYd47B0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "from PIL import Image\n",
        "\n",
        "# Read the input image , the input image is a PIL image or a torch tensor\n",
        "urllib.request.urlretrieve(\n",
        "  'https://assets3.thrillist.com/v1/image/2845547/1584x1056/scale;webp=auto;jpeg_quality=60;progressive.jpg',\n",
        "   \"progressive.jpg\")\n",
        "  \n",
        "img = Image.open(\"progressive.jpg\")\n",
        "\n",
        "# Adjust the sharpness of the image with the desired sharpness factor \n",
        "img_sharpness = transforms.functional.adjust_sharpness(img , sharpness_factor = 5.0)\n",
        "# visualize the sharpness adjusted image\n",
        "img_sharpness.show()"
      ],
      "metadata": {
        "id": "mc3XxoDVQEMl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_OITIZe69Blc"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}